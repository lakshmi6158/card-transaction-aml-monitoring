{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b2c5f6-10f6-43ce-bb59-3387cbfe072a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/05/18 23:57:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/18 23:57:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark .sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"app1\").getOrCreate()\n",
    "from pyspark import SparkFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c4a4ab-217d-4e8b-94b1-f4982c32d6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_journal = spark.read.format(\"csv\") \\\n",
    " .option(\"header\", \"true\") \\\n",
    " .load('journal_information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1951fe7e-7583-4730-a8c5-8a7ea691b8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_large = spark.read.format(\"json\") \\\n",
    " .option(\"header\", \"true\") \\\n",
    " .load('large.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefc8a95-8f68-40f6-90af-8e14234c7fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Journal Name: string, ISSN: string, EISSN: string, Category & Journal Quartiles: string, Citations: string, JCI: string, percentageOAGold: string, IF: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "769da636-aa6f-45ee-975a-44db8117511e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[authors: array<struct<authorId:string,name:string>>, citationcount: bigint, corpusid: bigint, externalids: struct<ACL:string,ArXiv:string,CorpusId:string,DBLP:string,DOI:string,MAG:string,PubMed:string,PubMedCentral:string>, influentialcitationcount: bigint, isopenaccess: boolean, journal: struct<name:string,pages:string,volume:string>, publicationdate: string, publicationtypes: array<string>, publicationvenueid: string, referencecount: bigint, s2fieldsofstudy: array<struct<category:string,source:string>>, title: string, url: string, venue: string, year: bigint]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327605ef-b48a-45cd-acaa-7bf8a62af104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def filtered_df(df):\n",
    "    return df.filter(F.col(\"journal.name\").isNotNull()).where(df['journal.name']!= \"\")\n",
    "\n",
    "def filtered_journal(df):\n",
    "    return df.withColumn(\"IF\",df[\"IF\"].cast(DoubleType()))\n",
    "\n",
    "#UDF to extract authors \n",
    "def extract_authors(df):\n",
    "    return df.select(F.explode('authors').alias('author'),\"journal\")\n",
    "\n",
    "#UDF to count num of authors\n",
    "def count_authors(df):\n",
    "    return df.withColumn(\"num_authors\", F.size(F.col(\"authors\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a13fa634-e534-41ab-ba0b-a1d792acf8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All papers have unique IDs. 150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Programmatically confirm that all papers have unique IDs and output the number of papers in the file.\n",
    "\n",
    "def checkForDuplicates(df):\n",
    "    if df.select(\"corpusid\").distinct().count() == df.count():\n",
    "        print(\"All papers have unique IDs.\", df.count())\n",
    "    else:\n",
    "        print(\"There are papers with non-unique IDs.\")\n",
    "\n",
    "checkForDuplicates(df_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a651f1f2-5417-4fd9-822b-231cc508d95b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of authors per paper: 2.81628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#What is the average number of authors per paper?\n",
    "\n",
    "# apply the UDF function to the dataframe\n",
    "df = count_authors(df_large)\n",
    "\n",
    "# calculate the average number of authors per paper\n",
    "avg_authors_per_paper = df.agg(F.avg(\"num_authors\")).first()[0]\n",
    "\n",
    "print(\"Average number of authors per paper:\", avg_authors_per_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7f2da1-3cfd-48db-8efc-f147d443c48a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct journals: 33916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_df = filtered_df(df_large)\n",
    "num_journals = filtered_df.select(F.col(\"journal.name\")).distinct().count()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of distinct journals:\", num_journals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b672e38d-6514-4503-9390-47b5d1434a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different journals: 33916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "papers_rdd = filtered_df.rdd\n",
    "journal_names_rdd = papers_rdd.map(lambda paper: paper['journal']['name'])\n",
    "unique_journal_names_count = journal_names_rdd.distinct().count()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of different journals: {unique_journal_names_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2974d852-efc1-4bee-a516-35d779b69bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                 (0 + 1) / 1][Stage 32:=========>        (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|              author|publications|\n",
      "+--------------------+------------+\n",
      "|{2149377746, B. N...|          23|\n",
      "|{90537224, S. Suk...|          16|\n",
      "|{88842366, Z. Sor...|          16|\n",
      "|{49898687, M. Kumar}|          15|\n",
      "|   {null, Anonymous}|          10|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "authors_df = extract_authors(df_large)\n",
    "authors = authors_df.groupBy('author.authorid', 'author.name').agg(F.count('*').alias('publications')).orderBy(F.desc('publications'))\n",
    "\n",
    "# Combine authorid and name back to dictionary format\n",
    "authors = authors.select(F.struct(authors['authorid'], authors['name']).alias('author'), 'publications').limit(5)\n",
    "\n",
    "# Display the result\n",
    "authors.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dbaa6f6-172c-48bb-a1d4-f00253eefeab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                 (0 + 1) / 1][Stage 37:=========>        (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------+\n",
      "|              author|cumulative_impact_factor|\n",
      "+--------------------+------------------------+\n",
      "|{2155504929, Ying...|                  93.832|\n",
      "|{144797099, M. Vi...|                  92.238|\n",
      "|{5152451, L. Andr...|                  92.238|\n",
      "| {49900836, H. Wood}|                  90.422|\n",
      "|{7695437, A. M. R...|                  87.899|\n",
      "+--------------------+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "paper_df = df_large\n",
    "journal_df = filtered_journal(df_journal)\n",
    "\n",
    "# Join paper and journal dataframes\n",
    "joined_df = paper_df.join(journal_df, paper_df[\"journal.name\"] == journal_df[\"Journal Name\"], \"left\")\n",
    "\n",
    "# Group by author and calculate the cumulative impact factor\n",
    "author_impact_factor = joined_df.withColumn(\"impact_factor_contribution\", F.coalesce(joined_df[\"IF\"], F.lit(0))) \\\n",
    "                                .select(F.explode('authors').alias('author'), 'impact_factor_contribution') \\\n",
    "                                .groupBy(\"author.authorId\", \"author.name\") \\\n",
    "                                .agg(F.sum(\"impact_factor_contribution\").alias(\"cumulative_impact_factor\")) \\\n",
    "                                .orderBy(F.desc(\"cumulative_impact_factor\")) \\\n",
    "                                .limit(5) \\\n",
    "                                .select(F.struct(\"authorId\", \"name\").alias(\"author\"), \"cumulative_impact_factor\")\n",
    "\n",
    "# Display the result\n",
    "author_impact_factor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb01699e-e6a6-425f-85b6-72c0e72bcc59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                 (0 + 1) / 1][Stage 47:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+\n",
      "|year|count(corpusid)|\n",
      "+----+---------------+\n",
      "|2010|            112|\n",
      "|2011|            139|\n",
      "|2012|            165|\n",
      "|2013|            178|\n",
      "|2014|            241|\n",
      "|2015|            243|\n",
      "|2016|            283|\n",
      "|2017|            329|\n",
      "|2018|            365|\n",
      "|2019|            396|\n",
      "|2020|            444|\n",
      "+----+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "# Paper information DataFrame\n",
    "paper_df = df_large.select(\"corpusid\",\"journal.name\",\"year\").withColumn(\"journal_name\", F.trim(F.col(\"name\"))).filter(F.col(\"journal_name\")!=\"\")\n",
    "\n",
    "# Journal information DataFrame\n",
    "journal_df = df_journal.select(\"Journal Name\",\"IF\").withColumn(\"Journal Name\", F.trim(F.col(\"Journal Name\"))).filter(F.col(\"Journal Name\")!=\"\")\n",
    "\n",
    "# Filter papers with impact factor > 1\n",
    "filtered_df = paper_df.join(journal_df, paper_df['journal_name'] == journal_df['Journal Name'], \"inner\")\n",
    "filtered_df = filtered_df.filter((F.col(\"IF\").cast(FloatType())) > 1)\n",
    "\n",
    "# Extract publication year from publicationdate column\n",
    "#filtered_df = filtered_df.withColumn(\"publication_year\", F.year(F.col(\"publicationdate\")))\n",
    "\n",
    "# Count publications for each year between 2010-2020\n",
    "publications_per_year = filtered_df.filter(F.col(\"year\").between(2010, 2020)) \\\n",
    "                                        .groupBy(\"year\") \\\n",
    "                                        .agg(F.countDistinct(\"corpusid\")) \\\n",
    "                                        .orderBy(\"year\")\n",
    "\n",
    "# Display the result\n",
    "publications_per_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e63dca-400f-43ab-ae17-8ec106d7b3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519a4b9-0d35-4f08-8c71-09c0c5a72e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2d1dd-601a-45c1-8c91-d8004c62c508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdbd5f3-9d70-43a0-ba2b-5dcd9adbcbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec190b66-bdb9-474b-a5ac-062fca2cb6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff32e612-8f33-4982-8000-a5042f875e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f919229d-3a9a-4fe6-b1e3-6e2054ee6cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20657a7-2c38-4e2e-b012-19823709aa71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a835f7-aa24-4e29-9a0a-2e911e2147bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
